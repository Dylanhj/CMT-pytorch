{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "violent-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-*- coding: utf-8 -*-\n",
    "@datetime: 2021-06-28\n",
    "@author  : jiangmingchao@joyy.sg\n",
    "@describe: Imagenet dataset\n",
    "\"\"\"\n",
    "from math import e\n",
    "import torch\n",
    "import random \n",
    "import numpy as np \n",
    "import urllib.request as urt \n",
    "\n",
    "from PIL import Image \n",
    "from io import BytesIO\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.transforms import transforms as imagenet_transforms\n",
    "from timm.data.auto_augment import rand_augment_transform, augment_and_mix_transform, auto_augment_transform\n",
    "from timm.data.transforms import _pil_interp\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                image_file,\n",
    "                train_phase,\n",
    "                input_size,\n",
    "                crop_size,\n",
    "                shuffle = True ,\n",
    "                interpolation='random',\n",
    "                auto_augment = None, \n",
    "                color_prob = 0.4,\n",
    "                hflip_prob = 0.5,\n",
    "                vflip_prob = 0.0,\n",
    "\n",
    "                ) -> None:\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.image_file = image_file\n",
    "        self.image_list = [x.strip() for x in open(self.image_file).readlines()]\n",
    "        self.length = [x for x in range(len(self.image_list))]\n",
    "        self.train_phase = train_phase\n",
    "        self.input_size = input_size\n",
    "        self.crop_size = crop_size\n",
    "        self.shuffle = shuffle\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        self.hflip_prob = hflip_prob\n",
    "        self.vflip_prob = vflip_prob\n",
    "        \n",
    "        if self.shuffle and self.train_phase:\n",
    "            for _ in range(10):\n",
    "                random.shuffle(self.image_list)\n",
    "\n",
    "        self.colorjitter_prob = None if color_prob is None else (color_prob, )*3 \n",
    "        self.auto_augment = auto_augment\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "        # train\n",
    "        if self.train_phase:\n",
    "            basic_tf = [\n",
    "                imagenet_transforms.RandomResizedCrop((self.crop_size, self.crop_size)),\n",
    "                imagenet_transforms.RandomHorizontalFlip(self.hflip_prob),\n",
    "                imagenet_transforms.RandomVerticalFlip(self.vflip_prob),\n",
    "            ]\n",
    "\n",
    "            auto_tf = []\n",
    "            if self.auto_augment:\n",
    "                assert isinstance(auto_augment, str)\n",
    "                if isinstance(self.crop_size, (tuple, list)):\n",
    "                    img_size_min = min(self.crop_size)\n",
    "                else:\n",
    "                    img_size_min = self.crop_size \n",
    "                \n",
    "                aa_params = dict(\n",
    "                    translate_dict = int(img_size_min * 0.45),\n",
    "                    img_mean = tuple([min(255, round(255 * x)) for x in self.mean])\n",
    "                )\n",
    "                if self.interpolation and self.interpolation != \"random\":\n",
    "                    aa_params['interpolation'] = _pil_interp(self.interpolation)\n",
    "                # rand aug\n",
    "                if auto_augment.startswith('rand'):\n",
    "                    auto_tf += [rand_augment_transform(auto_augment, aa_params)]\n",
    "                # augmix\n",
    "                elif auto_augment.startswith('augmix'):\n",
    "                    aa_params['translate_pct'] = 0.3\n",
    "                    auto_tf += [augment_and_mix_transform(auto_augment, aa_params)]\n",
    "                # auto aug\n",
    "                else:\n",
    "                    auto_tf += [auto_augment_transform(auto_augment, aa_params)]\n",
    "\n",
    "            if self.colorjitter_prob is not None:\n",
    "                auto_tf += [\n",
    "                    imagenet_transforms.ColorJitter(*self.colorjitter_prob)\n",
    "                ]\n",
    "\n",
    "            final_tf = [\n",
    "                imagenet_transforms.ToTensor(),\n",
    "                imagenet_transforms.Normalize(\n",
    "                    mean= self.mean,\n",
    "                    std= self.std \n",
    "                )\n",
    "            ]\n",
    "            self.data_aug = imagenet_transforms.Compose(\n",
    "                basic_tf + auto_tf \n",
    "            )\n",
    "            \n",
    "            print(self.data_aug)\n",
    "\n",
    "        # test \n",
    "        else:\n",
    "            self.data_aug = imagenet_transforms.Compose([\n",
    "                imagenet_transforms.Resize(self.input_size),\n",
    "                imagenet_transforms.CenterCrop((self.crop_size, self.crop_size)),\n",
    "                imagenet_transforms.ToTensor(),\n",
    "                imagenet_transforms.Normalize(\n",
    "                    mean = self.mean,\n",
    "                    std = self.std \n",
    "                )\n",
    "            ])\n",
    "            \n",
    "    def _decode_image(self, image_path):\n",
    "        if \"http\" in image_path:\n",
    "            image = Image.open(BytesIO(urt.urlopen(image_path).read()))\n",
    "        else:\n",
    "            image = Image.open(image_path)\n",
    "        \n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                line = self.image_list[index]\n",
    "                image_path, image_label = line.split(',')[0], line.split(',')[1]\n",
    "                image = self._decode_image(image_path)\n",
    "                image = self.data_aug(image)\n",
    "                label = torch.from_numpy(np.array(int(image_label))).long()\n",
    "                return image, label \n",
    "            except Exception as e:\n",
    "                index = random.choice(self.length)\n",
    "                print(f\"The exception is {e}, image path is {image_path}!!!\")\n",
    "                \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "comprehensive-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ImageDataset object at 0x7fddd21ec950>\n",
      "50000\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_file = \"/data/jiangmingchao/data/dataset/imagenet/val_oss_imagenet_128w.txt\"\n",
    "train_dataset = ImageDataset(\n",
    "    image_file=train_file,\n",
    "    train_phase=False,\n",
    "    input_size = 224, \n",
    "    crop_size= 224,\n",
    "    shuffle=False,\n",
    "    interpolation='bilinear',\n",
    "    auto_augment=\"rand\",\n",
    "    color_prob = None,\n",
    "    hflip_prob = 0.0,\n",
    "    vflip_prob = 0.0\n",
    "    \n",
    ")\n",
    "print(train_dataset)\n",
    "print(len(train_dataset))\n",
    "for _ in range(10):\n",
    "    for idx, data in enumerate(train_dataset):\n",
    "#         plt.figure()\n",
    "#         plt.imshow(data[0])\n",
    "        print(data[0].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "desirable-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "absent-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 3, 1, 1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 3, 1, 1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "built-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 3, 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "excited-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "helpful-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "alert-samoa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "developed-tuning",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Net' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-aeb51750e7c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'Net' object has no attribute 'module'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-exhibition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python37964bit8afb061195f148c295ce14825227ea77"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
